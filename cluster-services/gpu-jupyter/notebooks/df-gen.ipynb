{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e870e029-911b-4252-8c54-34bf29e07184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667aae3d-70c6-4a0c-86d4-09ce16e2e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to assign CPU consumption based on thirds\n",
    "def set_cpu_thresholds(remaining_entries, current_index, total_entries):\n",
    "    global initial_cpu\n",
    "    global applied_cpu\n",
    "\n",
    "    third_size = remaining_entries // 3  # Divide remaining entries into three parts\n",
    "    threshold_index = total_entries - remaining_entries  # Starting index of remaining entries\n",
    "\n",
    "    if current_index < threshold_index + third_size:\n",
    "        # First third\n",
    "        initial_cpu = round(random.uniform(0.2,1.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.8, 0.99), 2)  # Quota of 80% to 99%\n",
    "    elif current_index < threshold_index + 2 * third_size:\n",
    "        # Second third\n",
    "        initial_cpu = round(random.uniform(2.0, 8.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.1, 0.99), 2)  # Quota of 10% to 99%\n",
    "    else:\n",
    "        # Third third equal to second third\n",
    "        initial_cpu = round(random.uniform(2, 8.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.1, 0.99), 2)  # Quota of 10% to 99%\n",
    "# Function to assign memory consumption based on thirds\n",
    "def set_memory_thresholds(remaining_entries, current_index, total_entries):\n",
    "    global initial_avg_memory_consumption\n",
    "    global applied_memory_consumption\n",
    "    \n",
    "    third_size = remaining_entries // 3  # Divide remaining entries into three parts\n",
    "    threshold_index = total_entries - remaining_entries  # Starting index of remaining entries\n",
    "\n",
    "    if current_index < threshold_index + third_size:\n",
    "        # First third\n",
    "        initial_avg_memory_consumption = round(random.uniform(80, 199), 2)\n",
    "        applied_memory_consumption = round(random.uniform(0.8, 0.99), 2)\n",
    "    elif current_index < threshold_index + 2 * third_size:\n",
    "        # Second third\n",
    "        initial_avg_memory_consumption = round(random.uniform(200, 799), 2)\n",
    "        applied_memory_consumption = round(random.uniform(0.5, 0.99), 2) # Quota of 50% to 99%\n",
    "    else:\n",
    "        # Third third\n",
    "        initial_avg_memory_consumption = round(random.uniform(800, 2000), 2)\n",
    "        applied_memory_consumption = round(random.uniform(0.1, 0.99), 2)    # Quota of 10% to 99%\n",
    "\n",
    "\n",
    "# Function to assign CPU consumption based on thirds\n",
    "def set_cpu_thresholds_latency(remaining_entries, current_index, total_entries):\n",
    "    global initial_cpu\n",
    "    global applied_cpu\n",
    "\n",
    "    third_size = remaining_entries // 3  # Divide remaining entries into three parts\n",
    "    threshold_index = total_entries - remaining_entries  # Starting index of remaining entries\n",
    "\n",
    "    if current_index < threshold_index + third_size:\n",
    "        # First third\n",
    "        initial_cpu = round(random.uniform(0.2,1.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.8, 0.99), 2)  # Quota of 80% to 99%\n",
    "    elif current_index < threshold_index + 2 * third_size:\n",
    "        # Second third\n",
    "        initial_cpu = round(random.uniform(2.0, 8.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.1, 0.99), 2)  # Quota of 10% to 99%\n",
    "    else:\n",
    "        # Third third equal to second third\n",
    "        initial_cpu = round(random.uniform(2, 8.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.1, 0.99), 2)  # Quota of 10% to 99%\n",
    "# Function to assign memory consumption based on thirds\n",
    "def set_memory_thresholds_latency(remaining_entries, current_index, total_entries):\n",
    "    global initial_avg_memory_consumption\n",
    "    global applied_memory_consumption\n",
    "    \n",
    "    third_size = remaining_entries // 3  # Divide remaining entries into three parts\n",
    "    threshold_index = total_entries - remaining_entries  # Starting index of remaining entries\n",
    "\n",
    "    if current_index < threshold_index + third_size:\n",
    "        # First third\n",
    "        initial_avg_memory_consumption = round(random.uniform(80, 199), 2)\n",
    "        applied_memory_consumption = round(random.uniform(0.1, 1.99), 2)\n",
    "    elif current_index < threshold_index + 2 * third_size:\n",
    "        # Second third\n",
    "        initial_avg_memory_consumption = round(random.uniform(200, 799), 2)\n",
    "        applied_memory_consumption = round(random.uniform(0.2, 1.99), 2) # Quota of 50% to 99%\n",
    "    else:\n",
    "        # Third third\n",
    "        initial_avg_memory_consumption = round(random.uniform(800, 2000), 2)\n",
    "        applied_memory_consumption = round(random.uniform(0.1, 1.99), 2)    # Quota of 10% to 99%\n",
    "\n",
    "     # No changes in memory for this case\n",
    "def apply_scaling_memory(ranking, scale_up):\n",
    "    \"\"\"\n",
    "    Apply scaling logic to determine whether to scale up or scale down memory consumption.\n",
    "\n",
    "    Args:\n",
    "        initial_avg_memory_consumption (float): The initial average memory consumption.\n",
    "        replicas (int): The number of replicas.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - applied_memory_consumption (float): The adjusted memory consumption.\n",
    "            - label (int): The label indicating scaling direction (2 for scale up, 3 for scale down).\n",
    "            - skip (bool): Whether to skip this entry (True if the entry should be skipped).\n",
    "    \"\"\"\n",
    "    global initial_avg_memory_consumption\n",
    "    global applied_memory_consumption\n",
    "    global label\n",
    "    # Compute the minimum required change (90% of initial/replicas)\n",
    "    min_required_change = 0.9 * (initial_avg_memory_consumption / replicas)\n",
    "    min_percentage= min_required_change/initial_avg_memory_consumption\n",
    "\n",
    "\n",
    "    # Check if scaling down is invalid for a single replica\n",
    "    if replicas == 1 and not scale_up:\n",
    "        scale_up = True\n",
    "\n",
    "    # Apply scaling logic\n",
    "    if scale_up:  # Scale up case\n",
    "        applied_memory_consumption = round(initial_avg_memory_consumption +  (initial_avg_memory_consumption* random.uniform(min_percentage, min_percentage * (replicas/2))), 2)\n",
    "        label = 2\n",
    "    else:  # Scale down case\n",
    "        if ranking ==1 :\n",
    "            applied_memory_consumption =  round(initial_avg_memory_consumption-random.uniform(min_required_change, min_required_change*(replicas/2)), 2)\n",
    "        elif ranking ==2:\n",
    "             applied_memory_consumption = round( initial_avg_memory_consumption-random.uniform(min_required_change, min_required_change*(replicas/2)), 2)\n",
    "        elif ranking ==3:\n",
    "              applied_memory_consumption =  round(initial_avg_memory_consumption-random.uniform(min_required_change, min_required_change*(replicas/2)), 2)\n",
    "\n",
    "        label = 3\n",
    "\n",
    "\n",
    "\n",
    "def apply_scaling_cpu(ranking, scale_up):\n",
    "    \"\"\"\n",
    "    Apply scaling logic to determine whether to scale up or scale down memory consumption.\n",
    "\n",
    "    Args:\n",
    "        initial_avg_memory_consumption (float): The initial average memory consumption.\n",
    "        replicas (int): The number of replicas.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - applied_memory_consumption (float): The adjusted memory consumption.\n",
    "            - label (int): The label indicating scaling direction (2 for scale up, 3 for scale down).\n",
    "            - skip (bool): Whether to skip this entry (True if the entry should be skipped).\n",
    "    \"\"\"\n",
    "    global initial_cpu\n",
    "    global applied_cpu\n",
    "    global label\n",
    "    # Compute the minimum required change (90% of initial/replicas)\n",
    "    min_required_change = 0.9 * (initial_cpu / replicas)\n",
    "    min_percentage= min_required_change/initial_cpu\n",
    "    # Decide scaling direction\n",
    "    \n",
    "\n",
    "    # Check if scaling down is invalid for a single replica\n",
    "    if replicas == 1 and not scale_up:\n",
    "        scale_up = True\n",
    "\n",
    "    # Apply scaling logic\n",
    "    if scale_up:  # Scale up case\n",
    "        applied_cpu = round(initial_cpu +  (initial_cpu*random.uniform(min_percentage, min_percentage * (replicas/2))), 2)\n",
    "        label = 2\n",
    "    else:  # Scale down case\n",
    "        if ranking ==1 :\n",
    "            applied_cpu = round(initial_cpu - (initial_cpu*random.uniform(min_percentage, min_percentage * (replicas/2))), 2)\n",
    "        elif ranking ==2:\n",
    "             applied_cpu = round(initial_cpu - (initial_cpu*random.uniform(min_percentage, min_percentage * (replicas/2))), 2)\n",
    "        elif ranking ==3:\n",
    "              applied_cpu = round(initial_cpu -  (initial_cpu*random.uniform(min_percentage, min_percentage * (replicas/2))), 2)\n",
    "        label = 3        \n",
    "# Function to assign CPU consumption based on thirds\n",
    "def set_cpu_thresholds_scaling(remaining_entries, current_index, total_entries, scale_up):\n",
    "    global initial_cpu\n",
    "    global applied_cpu\n",
    "\n",
    "    third_size = remaining_entries // 3  # Divide remaining entries into three parts\n",
    "    threshold_index = total_entries - remaining_entries  # Starting index of remaining entries\n",
    "\n",
    "    if current_index < threshold_index + third_size:\n",
    "        # First third\n",
    "        initial_cpu = round(random.uniform(1,2), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.8, 0.99), 2)  # Quota of 80% to 99%\n",
    "        apply_scaling_cpu(1, scale_up)\n",
    "    elif current_index < threshold_index + 2 * third_size:\n",
    "        # Second third\n",
    "        initial_cpu = round(random.uniform(2.0, 8.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.1, 0.99), 2)  # Quota of 10% to 99%\n",
    "        apply_scaling_cpu(2, scale_up)\n",
    "    else:\n",
    "        # Third third equal to second third\n",
    "        initial_cpu = round(random.uniform(4, 10), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.1, 0.99), 2)  # Quota of 10% to 99%\n",
    "        apply_scaling_cpu(3, scale_up)\n",
    "# Function to assign memory consumption based on thirds\n",
    "def set_memory_thresholds_scaling(remaining_entries, current_index, total_entries, scale_up):\n",
    "    global initial_avg_memory_consumption\n",
    "    global applied_memory_consumption\n",
    "    global replicas\n",
    "    third_size = remaining_entries // 3  # Divide remaining entries into three parts\n",
    "    threshold_index = total_entries - remaining_entries  # Starting index of remaining entries\n",
    "\n",
    "    if current_index < threshold_index + third_size:\n",
    "        # First third\n",
    "        initial_avg_memory_consumption = round(random.uniform(200, 600), 2)\n",
    "        #applied_memory_consumption = round(random.uniform(0.8, 0.99), 2)\n",
    "        apply_scaling_memory(1, scale_up)\n",
    "    elif current_index < threshold_index + 2 * third_size:\n",
    "        # Second third\n",
    "        initial_avg_memory_consumption = round(random.uniform(600, 1000), 2) \n",
    "        #applied_memory_consumption = round(random.uniform(0.5, 0.99), 2) # Quota of 50% to 99%\n",
    "        apply_scaling_memory(2, scale_up)\n",
    "    else:\n",
    "        # Third third\n",
    "        initial_avg_memory_consumption = round(random.uniform(1000, 2000) , 2)\n",
    "        #applied_memory_consumption = round(random.uniform(0.1, 0.99), 2)    # Quota of 10% to 99%\n",
    "        apply_scaling_memory(3, scale_up)\n",
    "\n",
    "# Function to assign CPU consumption based on thirds\n",
    "def set_cpu_thresholds_migration(remaining_entries, current_index, total_entries):\n",
    "    global initial_cpu\n",
    "    global applied_cpu\n",
    "\n",
    "    third_size = remaining_entries // 3  # Divide remaining entries into three parts\n",
    "    threshold_index = total_entries - remaining_entries  # Starting index of remaining entries\n",
    "\n",
    "    if current_index < threshold_index + third_size:\n",
    "        # First third\n",
    "        initial_cpu = round(random.uniform(0.2,1.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.01, 0.15), 2) # Quota of 80% to 99%\n",
    "    elif current_index < threshold_index + 2 * third_size:\n",
    "        # Second third\n",
    "        initial_cpu = round(random.uniform(2.0, 8.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.01, 0.15), 2) # Quota of 10% to 99%\n",
    "    else:\n",
    "        # Third third equal to second third\n",
    "        initial_cpu = round(random.uniform(2, 8.0), 2)  # Example CPU range\n",
    "        applied_cpu = round(random.uniform(0.01, 0.15), 2)  # Quota of 10% to 99%\n",
    "# Function to assign memory consumption based on thirds\n",
    "def set_memory_thresholds_migration(remaining_entries, current_index, total_entries):\n",
    "    global initial_avg_memory_consumption\n",
    "    global applied_memory_consumption\n",
    "    \n",
    "    third_size = remaining_entries // 3  # Divide remaining entries into three parts\n",
    "    threshold_index = total_entries - remaining_entries  # Starting index of remaining entries\n",
    "\n",
    "    if current_index < threshold_index + third_size:\n",
    "        # First third\n",
    "        initial_avg_memory_consumption = round(random.uniform(80, 199), 2)\n",
    "        applied_memory_consumption = round(random.uniform(0.01, 0.15), 2)\n",
    "    elif current_index < threshold_index + 2 * third_size:\n",
    "        # Second third\n",
    "        initial_avg_memory_consumption = round(random.uniform(200, 799), 2)\n",
    "        applied_memory_consumption = round(random.uniform(0.01, 0.15), 2) # Quota of 50% to 99%\n",
    "    else:\n",
    "        # Third third\n",
    "        initial_avg_memory_consumption = round(random.uniform(800, 1200), 2)\n",
    "        applied_memory_consumption = round(random.uniform(0.01, 0.15), 2)    # Quota of 10% to 99%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8964e6fa-9cbc-401a-98cc-55a70f0c5b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at ./datasets/df1_0_optimize.csv\n"
     ]
    }
   ],
   "source": [
    "# 0 : optimize and should apply if there are only small differences between initial and applied memory (around 29%). Valid for any number of replicas \n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# Number of entries to generate\n",
    "num_entries = 2000 # Adjust as needed\n",
    "deployment_ids = random.sample(range(10000000, 99999999), num_entries)\n",
    "\n",
    "# Generate the data\n",
    "data = []\n",
    "for i in range(num_entries):\n",
    "    deployment_id = deployment_ids[i]\n",
    "    replicas = random.randint(1, 6)  # Any number of replicas\n",
    "    if i <= num_entries * 0.33:  \n",
    "        remaining_entries = int(num_entries * 0.33)-1\n",
    "        set_memory_thresholds(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds(remaining_entries, i, num_entries)\n",
    "        \n",
    "    if i > num_entries * 0.33 and   i < num_entries * 0.66: \n",
    "        remaining_entries = int(num_entries * 0.66)- int(num_entries * 0.33)\n",
    "        set_memory_thresholds(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds(remaining_entries, i, num_entries)\n",
    "        applied_cpu = 1 \n",
    "    if i >= num_entries * 0.66: # generate cases where no changes in memory\n",
    "        remaining_entries = num_entries - int(num_entries * 0.66)\n",
    "        set_memory_thresholds(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds(remaining_entries, i, num_entries)\n",
    "        applied_memory_consumption = 1\n",
    " \n",
    "    initial_avg_latency = round(random.uniform(1, 60), 2)\n",
    "    latency_variation = random.uniform(-0.05, 0.05)  # 5% range latency tolerance\n",
    "    applied_latency = round(initial_avg_latency * (1 + latency_variation), 2)\n",
    "\n",
    "    data.append({\n",
    "        'deployment_id': deployment_id,\n",
    "        'replicas': 1,\n",
    "        'initial_cpu': initial_cpu,\n",
    "        'applied_cpu': round(applied_cpu*initial_cpu,2),  # Percentage format\n",
    "        'initial_avg_memory_consumption': initial_avg_memory_consumption,\n",
    "        'applied_memory_consumption': round(applied_memory_consumption*initial_avg_memory_consumption,2),  # Percentage format\n",
    "        'initial_avg_latency': initial_avg_latency,\n",
    "        'applied_latency': applied_latency,\n",
    "        'label': 0  # Optimization case\n",
    "    })\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(\"./datasets\", exist_ok=True)\n",
    "file_path = \"./datasets/df1_0_optimize.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(file_path, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file saved at {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8714d893-3f3f-40b6-90c5-c1809dc92526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at ./datasets/df2_1_latency.csv\n"
     ]
    }
   ],
   "source": [
    "# 1 : If latency is high or 0 > return None\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# Number of entries to generate\n",
    "num_entries = 3000 # Adjust as needed\n",
    "deployment_ids = random.sample(range(10000000, 99999999), num_entries)\n",
    "\n",
    "# Generate the data\n",
    "data = []\n",
    "for i in range(num_entries):\n",
    "    deployment_id = deployment_ids[i]\n",
    "    replicas = random.randint(1, 6)  # Any number of replicas\n",
    "    if i <= num_entries * 0.33:  \n",
    "        remaining_entries = int(num_entries * 0.33)-1\n",
    "        set_memory_thresholds_latency(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds(remaining_entries, i, num_entries)\n",
    "        initial_avg_latency = round(random.uniform(1, 60), 2)\n",
    "        latency_variation = random.uniform(0.08, 1) \n",
    "        applied_latency = round(initial_avg_latency * (1 + latency_variation), 2)\n",
    "    if i > num_entries * 0.33 and   i < num_entries * 0.66: \n",
    "        remaining_entries = int(num_entries * 0.66)- int(num_entries * 0.33)\n",
    "        set_memory_thresholds_latency(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds(remaining_entries, i, num_entries)\n",
    "        applied_cpu = 1 \n",
    "        initial_avg_latency = round(random.uniform(1, 60), 2)\n",
    "        latency_variation = random.uniform(0.08, 1) \n",
    "        applied_latency = round(initial_avg_latency * (1 + latency_variation), 2)\n",
    "    if i >= num_entries * 0.66 and   i < num_entries * 0.90: # generate cases where no changes in memory\n",
    "        remaining_entries = num_entries - int(num_entries * 0.66)\n",
    "        set_memory_thresholds_latency(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds(remaining_entries, i, num_entries)\n",
    "        applied_memory_consumption = 1\n",
    "        initial_avg_latency = round(random.uniform(1, 60), 2)\n",
    "        latency_variation = random.uniform(0.08, 1) \n",
    "        applied_latency = round(initial_avg_latency * (1 + latency_variation), 2)\n",
    "    if i > num_entries * 0.90: \n",
    "        remaining_entries = int(num_entries * 0.66)- int(num_entries * 0.33)\n",
    "        set_memory_thresholds_latency(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds(remaining_entries, i, num_entries)\n",
    "        initial_avg_latency = round(random.uniform(1, 60), 2)\n",
    "        applied_latency = -1\n",
    "        \n",
    "\n",
    "    data.append({\n",
    "        'deployment_id': deployment_id,\n",
    "        'replicas': replicas,\n",
    "        'initial_cpu': initial_cpu,\n",
    "        'applied_cpu': round(applied_cpu*initial_cpu,2),  # Percentage format\n",
    "        'initial_avg_memory_consumption': initial_avg_memory_consumption,\n",
    "        'applied_memory_consumption': round(applied_memory_consumption*initial_avg_memory_consumption,2),  # Percentage format\n",
    "        'initial_avg_latency': initial_avg_latency,\n",
    "        'applied_latency': applied_latency,\n",
    "        'label': 1  # Optimization case\n",
    "    })\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(\"./datasets\", exist_ok=True)\n",
    "file_path = \"./datasets/df2_1_latency.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(file_path, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file saved at {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3031482b-3464-475c-aed8-1defeda2b3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at ./datasets/df3_23_scaling.csv\n"
     ]
    }
   ],
   "source": [
    "# Number of entries to generate\n",
    "num_entries = 5000  # Adjust as needed\n",
    "deployment_ids = random.sample(range(10000000, 99999999), num_entries)\n",
    "\n",
    "# Generate the data\n",
    "data = []\n",
    "for i in range(num_entries):\n",
    "    deployment_id = deployment_ids[i]\n",
    "    replicas = random.randint(1, 6)  # Any number of replicas\n",
    "    scale_up = random.choice([True, False])\n",
    "    if i <= num_entries * 0.33:  # First third\n",
    "        remaining_entries = int(num_entries * 0.33)\n",
    "        set_memory_thresholds_scaling(remaining_entries, i, num_entries, scale_up)\n",
    "        set_cpu_thresholds_scaling(remaining_entries, i, num_entries, scale_up)\n",
    "    elif i > num_entries * 0.33 and i <= num_entries * 0.66:  # Second third\n",
    "        remaining_entries = int(num_entries * 0.66) - int(num_entries * 0.33)\n",
    "        set_memory_thresholds_scaling(remaining_entries, i, num_entries, scale_up)\n",
    "        set_cpu_thresholds(remaining_entries, i, num_entries)\n",
    "        applied_cpu = 1  # No changes in CPU\n",
    "    else:  # Third third\n",
    "        remaining_entries = num_entries - int(num_entries * 0.66)\n",
    "        set_memory_thresholds(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds_scaling(remaining_entries, i, num_entries, scale_up)\n",
    "        applied_memory_consumption = 1  # No changes in memory\n",
    "\n",
    "    # Latency logic\n",
    "    initial_avg_latency = round(random.uniform(1, 60), 2)\n",
    "    latency_variation = random.uniform(-0.05, 0.05)  # 5% range latency tolerance\n",
    "    applied_latency = round(initial_avg_latency * (1 + latency_variation), 2)\n",
    "\n",
    "    # Append the data\n",
    "    data.append({\n",
    "        'deployment_id': deployment_id,\n",
    "        'replicas': replicas,\n",
    "        'initial_cpu': initial_cpu,\n",
    "        'applied_cpu': applied_cpu,  # Percentage format\n",
    "        'initial_avg_memory_consumption': initial_avg_memory_consumption,\n",
    "        'applied_memory_consumption': applied_memory_consumption,  # Percentage format\n",
    "        'initial_avg_latency': initial_avg_latency,\n",
    "        'applied_latency': applied_latency,\n",
    "        'label': label  # Scaling\n",
    "    })\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(\"./datasets\", exist_ok=True)\n",
    "file_path = \"./datasets/df3_23_scaling.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(file_path, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file saved at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f59d0232-2408-45fb-ae66-1d18a6bcbaac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at ./datasets/df4_1_migrate.csv\n"
     ]
    }
   ],
   "source": [
    "# 0 : optimize and should apply if there are only small differences between initial and applied memory (around 29%). Valid for any number of replicas \n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "# Number of entries to generate\n",
    "num_entries = 2000 # Adjust as needed\n",
    "deployment_ids = random.sample(range(10000000, 99999999), num_entries)\n",
    "\n",
    "# Generate the data\n",
    "data = []\n",
    "for i in range(num_entries):\n",
    "    deployment_id = deployment_ids[i]\n",
    "    replicas = 1  # Any number of replicas\n",
    "    if i <= num_entries * 0.33:    # Changes in both\n",
    "        remaining_entries = int(num_entries * 0.33)-1\n",
    "        set_memory_thresholds_migration(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds_migration(remaining_entries, i, num_entries)\n",
    "        \n",
    "    if i > num_entries * 0.33 and   i < num_entries * 0.66:         #NO cpu changes\n",
    "        remaining_entries = int(num_entries * 0.66)- int(num_entries * 0.33)\n",
    "        set_memory_thresholds_migration(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds_migration(remaining_entries, i, num_entries)\n",
    "        applied_cpu = 1 \n",
    "    if i >= num_entries * 0.66: # No memory changes\n",
    "        remaining_entries = num_entries - int(num_entries * 0.66)\n",
    "        set_memory_thresholds_migration(remaining_entries, i, num_entries)\n",
    "        set_cpu_thresholds_migration(remaining_entries, i, num_entries)\n",
    "        applied_memory_consumption = 1\n",
    " \n",
    "    initial_avg_latency = round(random.uniform(1, 60), 2)\n",
    "    latency_variation = random.uniform(-0.05, 0.05)  # 5% range latency tolerance\n",
    "    applied_latency = round(initial_avg_latency * (1 + latency_variation), 2)\n",
    "\n",
    "    data.append({\n",
    "        'deployment_id': deployment_id,\n",
    "        'replicas': 1,\n",
    "        'initial_cpu': initial_cpu,\n",
    "        'applied_cpu': round(applied_cpu*initial_cpu,2),  # Percentage format\n",
    "        'initial_avg_memory_consumption': initial_avg_memory_consumption,\n",
    "        'applied_memory_consumption': round(applied_memory_consumption*initial_avg_memory_consumption,2),  # Percentage format\n",
    "        'initial_avg_latency': initial_avg_latency,\n",
    "        'applied_latency': applied_latency,\n",
    "        'label': 1  # Optimization case\n",
    "    })\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(\"./datasets\", exist_ok=True)\n",
    "file_path = \"./datasets/df4_1_migrate.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(file_path, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(f\"CSV file saved at {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95df1e94-3b19-4f8b-a49a-23bc4da9fbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
